# Статистический анализ данных: MLE/MLS и критерии проверки гипотез

Комплексный проект для статистического анализа данных с графическим интерфейсом, включающий:
- Оценку параметров распределений (MLE/MLS)
- Статистические критерии проверки гипотез (Граббса, Фишера, Стьюдента)
- Вычисление доверительных интервалов
- Визуализацию результатов
- GUI приложение на Qt 6.9.3 для macOS

## Возможности

### Оценка параметров распределений

- **MLE (Maximum Likelihood Estimation)** - Метод максимального правдоподобия
- **MLS (Minimum Least Squares)** - Метод наименьших квадратов по методу Агамирова
- Поддержка нормального распределения и распределения Вейбулла
- **Поддержка цензурированных данных** (правая цензура)

### Статистические критерии

- **Критерий Граббса** - выявление выбросов в выборке
- **Критерий Фишера** - сравнение дисперсий двух выборок
- **Критерий Стьюдента** - сравнение средних значений двух выборок
- **Однофакторный дисперсионный анализ (ANOVA)** - сравнение средних значений в нескольких группах
- **Критерий Шапиро-Уилка** - проверка нормальности распределения
- **Критерий ранга суммы Уилкоксона** - непараметрическое сравнение двух выборок

### Доверительные интервалы

- При известной σ (нормальное распределение)
- При неизвестной σ (распределение Стьюдента)
- При неизвестном μ (χ² распределение для дисперсии)
- Вычисление персентилей (квантилей) с 95% ДИ

### Визуализация

- Автоматическое построение графиков распределений
- Визуализация доверительных интервалов
- Графики результатов статистических критериев
- **GUI приложение на Qt 6.9.3** с интерактивными графиками

### Кроссплатформенность

- Linux, macOS, Windows
- Консольная версия и GUI версия

## Требования

### Все платформы

- **C++ компилятор** с поддержкой C++17 (g++, clang++, MSVC)
- **Boost Math Library** (версия 1.70+)
- **Python 3.7+** для визуализации
- **Python библиотеки**: numpy, matplotlib, scipy

### Установка зависимостей

#### Linux (Ubuntu/Debian)

```bash
sudo apt-get update
sudo apt-get install g++ libboost-math-dev python3 python3-pip python3-venv
```

#### macOS

```bash
# Установка Homebrew (если не установлен)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Установка зависимостей
brew install boost python3
```

#### Windows (MinGW/MSYS2)

1. Установите [MSYS2](https://www.msys2.org/)
2. В MSYS2 терминале:

```bash
pacman -S mingw-w64-x86_64-gcc mingw-w64-x86_64-boost python3 python3-pip
```

## Установка

### 1. Клонирование репозитория

```bash
git clone https://github.com/xloned/agamirovstats.git
cd agamirovstats
```

### 2. Установка Python зависимостей

#### Linux/macOS

```bash
python3 -m venv python/venv
source python/venv/bin/activate
pip install numpy matplotlib scipy
deactivate
```

#### Windows

```cmd
python -m venv python\venv
python\venv\Scripts\activate
pip install numpy matplotlib scipy
deactivate
```

### 3. Сборка проекта

#### Linux/macOS

```bash
make
```

#### Windows (MinGW)

```cmd
# Используйте специальный Makefile для Windows
mingw32-make -f Makefile.win
```

## Запуск

### Linux/macOS

```bash
make run
```

или

```bash
./mle_estimator
```

### Windows

```cmd
mle_estimator.exe
```

## GUI Приложение (macOS)

### Сборка GUI

```bash
cd gui
mkdir build && cd build
cmake -DCMAKE_PREFIX_PATH=/opt/homebrew/opt/qt@6 ..
cmake --build .
```

### Запуск GUI

```bash
./StatisticsGUI.app/Contents/MacOS/StatisticsGUI
```

### Возможности GUI

- Интерактивный редактор данных с добавлением/удалением значений
- Выбор типа распределения (нормальное/Вейбулла)
- Выбор метода оценки (MLE/MLS)
- Автоматическое применение статистических критериев (Граббса, Фишера, Стьюдента)
- Встроенная визуализация результатов с использованием Python
- Отображение доверительных интервалов и персентилей
- Экспорт результатов в текстовые файлы и изображения

## Структура проекта

```
alg2/
├── include/                           # Заголовочные файлы
│   ├── boost_distributions.h          # Обертки для Boost распределений
│   ├── confidence_intervals.h         # Доверительные интервалы
│   ├── mle_methods.h                  # MLE/MLS методы
│   ├── matrix_operations.h            # Операции с матрицами (Boost.uBLAS)
│   ├── nelder_mead.h                  # Метод Нелдера-Мида для оптимизации
│   ├── order.h                        # Медианные ранги
│   ├── statistical_tests.h            # Критерии Граббса, Фишера, Стьюдента
│   ├── anova.h                        # Однофакторный дисперсионный анализ
│   ├── shapiro_wilk.h                 # Критерий Шапиро-Уилка
│   └── wilcoxon_ranksum.h             # Критерий ранга суммы Уилкоксона
│
├── src/                               # Исходные файлы C++
│   ├── boost_distributions.cpp        # Реализация распределений
│   ├── confidence_intervals.cpp       # Вычисление ДИ
│   ├── mle_methods.cpp                # Общие MLE методы
│   ├── mle_normal.cpp                 # MLE для нормального распределения
│   ├── mle_weibull.cpp                # MLE для Вейбулла
│   ├── mls_normal.cpp                 # MLS для нормального распределения
│   ├── mls_weibull.cpp                # MLS для Вейбулла
│   ├── matrix_operations.cpp          # Матричные операции
│   ├── nelder_mead.cpp                # Оптимизация
│   ├── order.cpp                      # Вычисление медианных рангов
│   ├── statistical_tests.cpp          # Реализация статистических критериев
│   ├── anova.cpp                      # Дисперсионный анализ
│   ├── shapiro_wilk.cpp               # Критерий Шапиро-Уилка
│   └── wilcoxon_ranksum.cpp           # Критерий Уилкоксона
│
├── gui/                               # GUI приложение на Qt 6.9.3
│   ├── CMakeLists.txt                 # Сборка Qt проекта
│   ├── include/
│   │   ├── mainwindow.h               # Главное окно приложения
│   │   ├── chartviewer.h              # Виджет для отображения графиков
│   │   ├── dataeditor.h               # Редактор данных
│   │   └── statisticsworker.h         # Фоновые вычисления
│   ├── src/
│   │   ├── main.cpp                   # Точка входа GUI
│   │   ├── mainwindow.cpp             # Реализация главного окна
│   │   ├── chartviewer.cpp            # Отображение графиков
│   │   ├── dataeditor.cpp             # Редактирование данных
│   │   └── statisticsworker.cpp       # Статистические вычисления
│   └── ui/
│       └── mainwindow.ui              # Qt Designer UI файл
│
├── python/                            # Python скрипты для визуализации
│   ├── plot_normal.py                 # График нормального распределения
│   ├── plot_weibull.py                # График Вейбулла
│   ├── plot_t_distribution.py         # t-распределение
│   ├── plot_confidence_intervals.py   # Доверительные интервалы
│   ├── plot_percentiles.py            # Персентили
│   ├── plot_student.py                # Критерий Стьюдента
│   └── plot_grubbs.py                 # Критерий Граббса
│
├── input/                             # Входные данные (примеры)
│   ├── data_normal.txt                # Нормальное распределение
│   ├── data_weibull.txt               # Распределение Вейбулла
│   ├── data_censored_normal.txt       # Цензурированные данные (норм.)
│   └── data_censored_weibull.txt      # Цензурированные данные (Вейбулл)
│
├── output/                            # Результаты (создается автоматически)
│   ├── *.txt                          # Числовые результаты
│   └── *.png                          # Графики
│
├── references/                        # Референсные реализации
│   ├── boost.cpp                      # Примеры использования Boost
│   ├── mle_normal.cpp                 # Референс MLE
│   └── mls.cpp                        # Референс MLS
│
├── test/                              # Тесты
├── main.cpp                           # Главный файл консольной программы
├── Makefile                           # Makefile для Unix/macOS
├── Makefile.win                       # Makefile для Windows
└── README.md                          # Этот файл
```

## Результаты

После запуска программа создает следующие файлы в директории `output/`:

### Числовые результаты

- `mle_normal_complete.txt` - MLE для нормального распределения
- `mle_weibull_complete.txt` - MLE для Вейбулла
- `mls_normal_censored.txt` - MLS для нормального (цензурированные)
- `mls_weibull_censored.txt` - MLS для Вейбулла (цензурированные)
- `confidence_intervals.txt` - Доверительные интервалы
- `percentiles_normal.txt` - Персентили для нормального
- `percentiles_weibull.txt` - Персентили для Вейбулла

### Графики

- `plot_mle_normal.png` - График MLE для нормального
- `plot_mls_normal.png` - График MLS для нормального
- `plot_mle_weibull.png` - График MLE для Вейбулла
- `plot_mls_weibull.png` - График MLS для Вейбулла
- `plot_t_varying_df.png` - t-распределение (неизвестная σ)
- `plot_normal_varying_sigma.png` - Нормальное (известная σ)
- `plot_chi_squared.png` - χ² распределение (неизвестное μ)

## Формат входных данных

### Полные данные

Текстовый файл с одним значением на строку:

```
87.3
92.1
98.5
...
```

### Цензурированные данные

Текстовый файл с двумя колонками (значение и индикатор цензуры):

```
102.5 0
95.3 0
110.0 1
...
```

Индикатор: `0` = полное наблюдение, `1` = цензурированное (правая цензура)

## Теоретические основы

### 1. Метод максимального правдоподобия (MLE)

MLE находит параметры распределения, максимизирующие функцию правдоподобия:

**Функция правдоподобия:**

```text
L(θ | x₁, ..., xₙ) = ∏ᵢ f(xᵢ | θ)
```

**Логарифмическая функция правдоподобия:**

```text
ln L(θ) = Σᵢ ln f(xᵢ | θ)
```

#### Нормальное распределение N(μ, σ²)

**Плотность вероятности:**

```text
f(x) = (1/√(2πσ²)) × exp(-(x-μ)²/(2σ²))
```

**MLE оценки:**

```text
μ̂ = x̄ = (1/n) Σᵢ xᵢ
σ̂² = (1/n) Σᵢ (xᵢ - x̄)²
```

#### Распределение Вейбулла W(λ, k)

**Плотность вероятности:**

```text
f(x) = (k/λ) × (x/λ)^(k-1) × exp(-(x/λ)^k)
```

**MLE оценки:**

```text
λ̂ = (1/n × Σᵢ xᵢᵏ)^(1/k)
k решается численно из уравнения:
Σᵢ xᵢᵏ ln(xᵢ) / Σᵢ xᵢᵏ - 1/k = (1/n) Σᵢ ln(xᵢ)
```

### 2. Метод наименьших квадратов (MLS)

MLS по методу Агамирова использует линеаризацию функции распределения и медианные ранги.

**Медианный ранг i-го порядкового значения:**

```text
F̃ᵢ = (i - 0.3) / (n + 0.4)
```

#### Для нормального распределения

**Линеаризация:**

```text
Φ⁻¹(F̃ᵢ) = (xᵢ - μ) / σ
```

**Система нормальных уравнений:**

```text
| n      Σxᵢ    | | a |   | Σzᵢ    |
| Σxᵢ    Σxᵢ²   | | b | = | Σxᵢzᵢ  |
```

где `zᵢ = Φ⁻¹(F̃ᵢ)` - квантили стандартного нормального распределения

**Оценки параметров:**

```text
σ̂ = 1/b
μ̂ = -a/b
```

#### Для распределения Вейбулла

**Линеаризация:**

```text
ln(-ln(1 - F̃ᵢ)) = k × ln(xᵢ) - k × ln(λ)
```

**Решается аналогично через МНК для:**

```text
yᵢ = ln(-ln(1 - F̃ᵢ))
```

### 3. Доверительные интервалы

#### При известной σ (Z-распределение)

```text
μ ∈ [x̄ - z_{α/2} × σ/√n, x̄ + z_{α/2} × σ/√n]
```

#### При неизвестной σ (t-распределение Стьюдента)

```text
μ ∈ [x̄ - t_{α/2}(n-1) × s/√n, x̄ + t_{α/2}(n-1) × s/√n]
```

где `s² = 1/(n-1) Σᵢ(xᵢ - x̄)²` - несмещенная оценка дисперсии

#### Для дисперсии (χ² распределение)

```text
σ² ∈ [(n-1)s²/χ²_{α/2}(n-1), (n-1)s²/χ²_{1-α/2}(n-1)]
```

### 4. Статистические критерии

#### Критерий Граббса (выявление выбросов)

**Назначение:** Обнаружение аномальных значений (выбросов) в выборке из нормального распределения.

**Когда применяется:**
- При первичном анализе данных для выявления грубых ошибок измерений
- Перед применением параметрических методов, чувствительных к выбросам
- В контроле качества для обнаружения бракованных изделий
- При анализе экспериментальных данных для удаления аномальных наблюдений

**Предположения:**
- Выборка должна быть из нормального распределения (без выбросов)
- Может быть только один выброс (для множественных выбросов используется последовательное применение)

**Статистика:**

```text
G = max|xᵢ - x̄| / s
```

где:
- `xᵢ` - подозрительное значение (максимально удаленное от среднего)
- `x̄` - выборочное среднее
- `s` - выборочное стандартное отклонение

**Критическое значение (двусторонний критерий):**

```text
G_crit = ((n-1)/√n) × √(t²_{α/(2n)}(n-2) / (n - 2 + t²_{α/(2n)}(n-2)))
```

**Решение:** Если `G > G_crit`, то наблюдение является выбросом и может быть исключено.

**Пример использования:**
При измерении прочности 20 образцов получены значения 100-110 МПа, но одно значение равно 150 МПа. Критерий Граббса поможет определить, является ли это значение статистически значимым выбросом или естественной вариацией.

#### Критерий Фишера (сравнение дисперсий)

**Назначение:** Проверка гипотезы об равенстве дисперсий (вариаций) двух нормальных распределений.

**Когда применяется:**
- Перед применением критерия Стьюдента для выбора его правильной модификации
- При сравнении точности двух методов измерения или приборов
- В контроле качества для сравнения стабильности технологических процессов
- При проверке предпосылок дисперсионного анализа (ANOVA)
- Для определения, имеют ли две группы одинаковую изменчивость

**Предположения:**
- Обе выборки из нормальных распределений
- Выборки независимы
- Данные измерены в интервальной или отношений шкале

**Статистика:**

```text
F = s₁² / s₂²  (где s₁² ≥ s₂²)
```

где:
- `s₁²` - большая из двух выборочных дисперсий
- `s₂²` - меньшая из двух выборочных дисперсий

**Распределение:** F-распределение с (n₁-1, n₂-1) степенями свободы

**Гипотеза H₀:** σ₁² = σ₂² (дисперсии равны)
**Альтернатива H₁:** σ₁² ≠ σ₂² (дисперсии различны)

**Решение:** Если `F > F_{α/2}(n₁-1, n₂-1)`, то H₀ отвергается - дисперсии статистически различны.

**Пример использования:**
Сравнение точности двух станков: первый станок производит детали с разбросом размеров s₁=0.5 мм (n₁=25), второй - с s₂=0.3 мм (n₂=30). Критерий Фишера покажет, значимо ли различается точность станков.

#### Критерий Стьюдента (сравнение средних)

**Назначение:** Проверка гипотезы о равенстве математических ожиданий двух нормальных распределений.

**Когда применяется:**
- Сравнение эффективности двух методов обработки или технологий
- Оценка влияния фактора (до/после воздействия)
- Сравнение характеристик двух групп объектов
- A/B тестирование (сравнение двух версий)
- Клинические испытания (сравнение контрольной и экспериментальной групп)

**Предположения:**
- Обе выборки из нормальных распределений (или n₁, n₂ > 30 по ЦПТ)
- Выборки независимы
- Для классического t-критерия: дисперсии равны (проверяется критерием Фишера)

**Для равных дисперсий (классический t-критерий):**

```text
t = (x̄₁ - x̄₂) / (s_p × √(1/n₁ + 1/n₂))

где s_p² = ((n₁-1)s₁² + (n₂-1)s₂²) / (n₁ + n₂ - 2)
```

где:
- `x̄₁, x̄₂` - выборочные средние
- `s_p²` - объединенная (pooled) оценка дисперсии
- `n₁, n₂` - размеры выборок

**Степени свободы:** df = n₁ + n₂ - 2

**Для неравных дисперсий (Welch's t-test):**

```text
t = (x̄₁ - x̄₂) / √(s₁²/n₁ + s₂²/n₂)

df = (s₁²/n₁ + s₂²/n₂)² / ((s₁²/n₁)²/(n₁-1) + (s₂²/n₂)²/(n₂-1))
```

Приближение Уэлча-Саттертуэйта для числа степеней свободы используется, когда дисперсии неравны.

**Гипотеза H₀:** μ₁ = μ₂ (средние значения равны)
**Альтернатива H₁:** μ₁ ≠ μ₂ (средние различны) - двусторонний критерий
Или H₁: μ₁ > μ₂ / μ₁ < μ₂ - односторонний критерий

**Решение:**
- Двусторонний: если `|t| > t_{α/2}(df)`, то H₀ отвергается
- Односторонний: если `t > t_α(df)` (или `t < -t_α(df)`), то H₀ отвергается

**Пример использования:**
Испытываются два типа батареек: тип A работает в среднем 50 часов (n₁=15, s₁=5ч), тип B - 48 часов (n₂=20, s₂=6ч). Критерий Стьюдента определит, есть ли статистически значимая разница в продолжительности работы.

### 5. Персентили (Квантили)

**Нормальное распределение:**

```text
x_p = μ + z_p × σ
```

где `z_p = Φ⁻¹(p)` - квантиль стандартного нормального распределения

**Распределение Вейбулла:**

```text
x_p = λ × (-ln(1-p))^(1/k)
```

**Доверительные интервалы для персентилей:**

Используется дельта-метод для получения асимптотической дисперсии оценки персентиля.

### 6. Обработка цензурированных данных

При проведении испытаний на надежность часто возникают ситуации, когда для части объектов не зафиксирован отказ (правое цензурирование).

#### Типы цензурирования

**Цензурирование типа I** - испытания прерываются в заданный момент времени t₀:
```text
xᵢ - наблюдаемое значение (отказ или время окончания испытаний)
rᵢ = 0 - если наблюдался отказ
rᵢ = 1 - если объект не отказал (цензурирован)
```

**Цензурирование типа II** - испытания прерываются после получения заданного числа отказов r < n:
```text
Наблюдаются первые r отказов из n испытуемых объектов
Остальные (n-r) объектов цензурированы
```

#### Функция правдоподобия для цензурированных данных

```text
L(θ) = ∏(i: rᵢ=0) f(xᵢ|θ) × ∏(i: rᵢ=1) S(xᵢ|θ)
```

где:
- `f(x|θ)` - плотность распределения
- `S(x|θ) = 1 - F(x|θ)` - функция надежности (вероятность не отказать до момента x)

#### Оценка Каплана-Мейера

Непараметрическая оценка функции распределения для цензурированных данных:

```text
F̂(t) = 1 - ∏(tᵢ≤t) (1 - dᵢ/nᵢ)
```

где:
- `tᵢ` - моменты наблюдаемых отказов
- `dᵢ` - число отказов в момент tᵢ
- `nᵢ` - число объектов под риском непосредственно перед моментом tᵢ

### 7. Ковариационные матрицы оценок параметров

#### MLE для нормального распределения с цензурированием

Информационная матрица Фишера:

```text
I(μ,σ) = | I₁₁  I₁₂ |
         | I₂₁  I₂₂ |
```

где для каждого цензурированного наблюдения с zᵢ = (xᵢ - μ)/σ:

```text
ψ(z) = φ(z)/(1 - Φ(z)) - функция риска (hazard function)

I₁₁ = (k + Σ(rᵢ=1) ψᵢ(ψᵢ - zᵢ)) / n
I₁₂ = I₂₁ = Σ(rᵢ=1) ψᵢ(zᵢ(ψᵢ - zᵢ) - 1) / n
I₂₂ = (2k + Σ(rᵢ=1) ψᵢzᵢ(zᵢ(ψᵢ - zᵢ) - 1)) / n
```

где k - число наблюдаемых отказов

Ковариационная матрица оценок:
```text
Cov(μ̂,σ̂) = I⁻¹(μ,σ)
```

#### Взвешенный МНК с ковариационной матрицей

Для учета корреляции между порядковыми статистиками используется обобщенный МНК:

```text
β̂ = (X^T V⁻¹ X)⁻¹ X^T V⁻¹ y
```

где:
- `V` - ковариационная матрица порядковых статистик
- `X` - матрица регрессоров
- `y` - вектор линеаризованных значений

Ковариационная матрица оценок:
```text
Cov(β̂) = (X^T V⁻¹ X)⁻¹
```

### 8. Метод "Up-and-Down" (метод лестницы)

Последовательный метод испытаний для оценки параметров распределения (часто используется для определения усталостной прочности).

#### Алгоритм

1. Начальное напряжение x₀ выбирается вблизи предполагаемого среднего
2. Если объект не отказал на уровне xᵢ → следующий уровень xᵢ₊₁ = xᵢ + d
3. Если объект отказал на уровне xᵢ → следующий уровень xᵢ₊₁ = xᵢ - d

где d - заранее выбранный шаг изменения уровня нагрузки

#### Оценки параметров

Для нормального распределения:

```text
μ̂ = x₀ + d(Σᵢ i·nᵢ / N ± 1/2)
σ̂² = 1.62 d² (Σᵢ i²·nᵢ / N - (Σᵢ i·nᵢ / N)²) + 0.029 d²
```

где:
- `nᵢ` - число испытаний на уровне i
- `N` - общее число испытаний
- Знак ± выбирается в зависимости от того, какой исход (отказ/не отказ) более редкий

### 9. Однофакторный дисперсионный анализ (One-way ANOVA)

**Назначение:** Проверка гипотезы о равенстве средних значений в k ≥ 2 группах.

**Когда применяется:**
- Сравнение эффективности нескольких методов, технологий или условий одновременно
- Проверка влияния одного категориального фактора на непрерывную переменную
- В экспериментах с несколькими независимыми группами
- Обобщение t-критерия Стьюдента на случай более двух групп

**Предположения:**
- Данные в каждой группе из нормального распределения
- Дисперсии в группах равны (гомоскедастичность)
- Наблюдения независимы

**Статистика (формулы 3.13-3.16):**

```text
F = MS_between / MS_within

где:
MS_between = SS_between / (m - 1)
MS_within = SS_within / (N - m)

SS_between = Σᵢ nᵢ(x̄ᵢ - x̄)²  - межгрупповая сумма квадратов
SS_within = ΣᵢΣⱼ(xᵢⱼ - x̄ᵢ)²  - внутригрупповая сумма квадратов
SS_total = SS_between + SS_within
```

**Распределение:** F ~ F(m-1, N-m) под H0

**Гипотеза H₀:** μ₁ = μ₂ = ... = μₘ (средние во всех группах равны)
**Альтернатива H₁:** хотя бы одно среднее отличается

**Решение:** Если `F > F_{α}(m-1, N-m)`, то H₀ отвергается.

**Таблица ANOVA:**
```
Источник вариации | SS         | df    | MS         | F        | p-value
------------------+------------+-------+------------+----------+---------
Между группами    | SS_between | m-1   | MS_between | F        | p
Внутри групп      | SS_within  | N-m   | MS_within  |          |
Всего             | SS_total   | N-1   |            |          |
```

**Пример использования:**
Сравнение урожайности при использовании 4 различных удобрений на 40 участках (по 10 на каждое удобрение). ANOVA покажет, есть ли значимые различия между удобрениями.

**Post-hoc анализ:**
Если H₀ отвергнута, для определения конкретных различающихся пар используются:
- Критерий Тьюки (Tukey HSD)
- Критерий Шеффе
- Критерий Бонферрони

### 10. Дополнительные статистические критерии

#### Критерий Бартлетта (однородность дисперсий для k групп)

**Назначение:** Проверка гипотезы об однородности (равенстве) дисперсий в k ≥ 2 группах.

**Когда применяется:**
- Перед проведением однофакторного дисперсионного анализа (ANOVA) для проверки предпосылки о равенстве дисперсий
- При сравнении изменчивости в нескольких группах одновременно (обобщение критерия Фишера на k групп)
- В многофакторных экспериментах для проверки гомоскедастичности
- При проверке стабильности технологического процесса в разных условиях

**Предположения:**
- Все выборки из нормальных распределений
- Выборки независимы
- Критерий чувствителен к отклонению от нормальности

**Статистика:**

```text
B = (N - k)ln(s²ₚ) - Σⱼ(nⱼ - 1)ln(s²ⱼ)
B' = B / C

где:
s²ₚ = Σⱼ(nⱼ - 1)s²ⱼ / (N - k) - объединенная дисперсия
C = 1 + (1/(3(k-1)))(Σⱼ 1/(nⱼ-1) - 1/(N-k)) - поправка Бартлетта
N = Σⱼ nⱼ - общий объем выборки
```

**Распределение:** χ² с (k-1) степенями свободы

**Гипотеза H₀:** σ₁² = σ₂² = ... = σₖ² (все дисперсии равны)
**Альтернатива H₁:** хотя бы одна дисперсия отличается от остальных

**Решение:** Если `B' > χ²_α(k-1)`, то H₀ отвергается.

**Пример использования:**
Сравнение стабильности размеров деталей, изготовленных на 4 разных станках. Перед применением ANOVA необходимо убедиться, что разброс размеров на всех станках примерно одинаков.

**Альтернативы:** Критерий Левена (более устойчив к отклонениям от нормальности), критерий Флигнера-Килина (непараметрический).

#### Критерий Шапиро-Уилка (проверка нормальности)

**Назначение:** Проверка гипотезы о том, что выборка получена из нормального распределения.

**Когда применяется:**
- Перед применением параметрических критериев (t-критерий, ANOVA), требующих нормальности
- При построении доверительных интервалов, основанных на предположении о нормальности
- В регрессионном анализе для проверки нормальности остатков
- При выборе между параметрическими и непараметрическими методами

**Предположения:**
- Рекомендуется для выборок размером 3 ≤ n ≤ 5000
- Обладает высокой мощностью для малых и средних выборок
- Один из наиболее мощных критериев нормальности

**Статистика:**

```text
W = (Σᵢ aᵢx₍ᵢ₎)² / Σᵢ(xᵢ - x̄)²
```

где:
- `x₍ᵢ₎` - упорядоченная выборка (x₍₁₎ ≤ x₍₂₎ ≤ ... ≤ x₍ₙ₎)
- `aᵢ` - специальные коэффициенты, вычисляемые по ожидаемым значениям порядковых статистик стандартного нормального распределения
- `W` ∈ [0, 1], причем чем ближе к 1, тем больше данные похожи на нормальное распределение

**Гипотеза H₀:** выборка из нормального распределения
**Альтернатива H₁:** выборка не из нормального распределения

**Решение:** Если `W < W_crit(α, n)`, то H₀ отвергается - распределение не является нормальным.

**Пример использования:**
Перед применением t-критерия для сравнения прочности двух материалов необходимо убедиться, что данные в каждой группе подчиняются нормальному распределению. Критерий Шапиро-Уилка даст наиболее надежный результат для выборок размером 15-20 объектов.

**Интерпретация:**
- W > 0.95 - обычно указывает на хорошее соответствие нормальному распределению
- W < 0.90 - сильное отклонение от нормальности
- При больших выборках (n > 100) критерий может быть слишком чувствительным к незначительным отклонениям

#### Критерий Андерсона-Дарлинга (проверка соответствия распределению)

**Назначение:** Проверка гипотезы о том, что выборка получена из заданного теоретического распределения (нормального, экспоненциального, Вейбулла и др.).

**Когда применяется:**
- Для проверки соответствия данных различным типам распределений
- В анализе надежности для проверки предположений о законе отказов
- Более мощная альтернатива критерию Колмогорова-Смирнова, особенно чувствительная к расхождениям в хвостах распределения
- При выборе подходящей модели распределения для данных

**Предположения:**
- Параметры распределения могут быть известны заранее или оценены по выборке
- Критерий дает больший вес расхождениям в хвостах, чем в центре распределения
- Более мощный, чем критерий Колмогорова-Смирнова

**Статистика:**

```text
A² = -n - (1/n)Σᵢ(2i - 1)[ln F(x₍ᵢ₎) + ln(1 - F(x₍ₙ₊₁₋ᵢ₎))]
```

где:
- `F(x)` - предполагаемая функция распределения
- `x₍ᵢ₎` - упорядоченная выборка
- Суммирование учитывает как левый, так и правый хвост распределения

**Модифицированная статистика:**

```text
A²* = A²(1 + 4/n - 25/n²)
```

Поправка компенсирует смещение при малых выборках.

**Гипотеза H₀:** выборка из заданного распределения F(x)
**Альтернатива H₁:** выборка не из распределения F(x)

**Решение:** Если `A²* > A²_crit(α)`, то гипотеза о соответствии распределению отвергается.

**Критические значения (для нормального распределения):**
- α = 0.10: A²_crit = 0.631
- α = 0.05: A²_crit = 0.752
- α = 0.025: A²_crit = 0.873
- α = 0.01: A²_crit = 1.035

**Пример использования:**
При анализе времени до отказа электронных компонентов необходимо выбрать между экспоненциальным и распределением Вейбулла. Критерий Андерсона-Дарлинга поможет определить, какое распределение лучше описывает данные, уделяя особое внимание редким событиям (большим временам отказа).

**Преимущества:**
- Более чувствителен к расхождениям в хвостах распределения по сравнению с критерием Колмогорова-Смирнова
- Применим к различным семействам распределений
- Хорошо работает для выборок малого и среднего размера

#### Критерий ранга суммы Уилкоксона (Wilcoxon Rank-Sum Test / Mann-Whitney U Test)

**Назначение:** Непараметрическая проверка гипотезы о равенстве распределений двух независимых выборок.

**Когда применяется:**
- Когда нарушены предположения t-критерия Стьюдента (ненормальность, неравные дисперсии)
- При наличии выбросов в данных
- Для данных в порядковой шкале (ранги, оценки)
- Когда важно сравнить общие распределения, а не только средние
- При малых выборках, где проверка нормальности ненадежна

**Предположения:**
- Выборки независимы
- Данные измерены как минимум в порядковой шкале
- Не требуется нормальность распределения
- Более устойчив к выбросам, чем t-критерий

**Статистика (формулы 3.32-3.35):**

```text
W = Σ Rᵢ  - сумма рангов первой выборки

где:
Rᵢ - ранг i-го наблюдения из первой выборки
     в объединенной упорядоченной выборке

Связь с U-статистикой Манна-Уитни:
U₁ = W - n₁(n₁ + 1)/2
U₂ = n₁n₂ - U₁
U = min(U₁, U₂)
```

**Для больших выборок (n₁, n₂ > 10) - нормальное приближение:**

```text
E[W] = n₁(n₁ + n₂ + 1)/2
Var[W] = n₁n₂(n₁ + n₂ + 1)/12

Z = (W - E[W] - 0.5) / √Var[W]  с поправкой на непрерывность
```

**Поправка на связи (формула 3.35):**
При наличии одинаковых значений (ties) применяется коррекция дисперсии:

```text
Var[W] = n₁n₂[(n₁ + n₂ + 1)/12 - Σ(tᵢ³ - tᵢ)/(12(N-1))]

где tᵢ - размер i-й группы связанных значений
```

**Гипотеза H₀:** F₁(x) = F₂(x) (распределения одинаковы)
**Альтернатива H₁:** F₁(x) ≠ F₂(x) (распределения различаются)

**Решение:**
- Для малых выборок: используются точные таблицы распределения W
- Для больших выборок: если |Z| > Z_{α/2}, то H₀ отвергается

**Пример использования:**
Сравнение уровня удовлетворенности клиентов двух магазинов по шкале от 1 до 10. Данные не нормальны и имеют выбросы. Критерий Уилкоксона даст надежный результат без предположения о нормальности.

**Эффективность:**
- При нормальных данных: эффективность ≈ 95% от t-критерия
- При ненормальных данных: может быть более мощным, чем t-критерий
- Робастность: не чувствителен к выбросам

**Интерпретация:**
Критерий проверяет, имеет ли одна группа тенденцию к более высоким значениям, чем другая, основываясь на рангах, а не на абсолютных значениях.

### 10. Непараметрические методы

Непараметрические методы не требуют предположений о виде распределения и устойчивы к выбросам. Применяются когда:
- Нарушены предположения параметрических критериев (ненормальность, гетероскедастичность)
- Данные измерены в порядковой шкале
- Малые выборки, где проверка нормальности ненадежна
- Присутствуют выбросы или асимметричные распределения

#### Знаковый критерий (Sign test)

**Назначение:** Проверка гипотезы о значении медианы или сравнение парных наблюдений.

**Когда применяется:**
- Самый простой непараметрический критерий для одной выборки
- Для парных наблюдений (до/после) когда критерий Вилкоксона неприменим
- Когда можно оценить только знак разности, но не её величину
- При сильно асимметричных распределениях или наличии выбросов

**Предположения:**
- Минимальные: требуется только возможность сравнить наблюдения с заданным значением
- Данные должны быть независимыми
- Менее мощный, чем критерий Вилкоксона, но более робастный

**Гипотеза H₀:** Med(X) = m₀ (медиана равна заданному значению)

**Статистика:**

```text
S = число наблюдений xᵢ > m₀
```

При H₀: `S ~ Binomial(n, 0.5)` - биномиальное распределение с p = 0.5

**Решение:**
- Для малых n: используются точные биномиальные вероятности
- Для больших n (обычно n > 20): нормальная аппроксимация
  ```
  Z = (S - n/2) / √(n/4)
  ```

**Пример использования:**
После введения нового технологического процесса измерено время обработки 30 деталей. Исторически медианное время было 5 минут. Знаковый критерий проверит, изменилась ли медиана (подсчитаем, сколько деталей обрабатывается быстрее 5 минут vs медленнее).

#### Критерий Вилкоксона (Wilcoxon signed-rank test)

**Назначение:** Проверка гипотезы о медиане для одной выборки или сравнение парных наблюдений с учетом величины различий.

**Когда применяется:**
- Непараметрическая альтернатива парному t-критерию
- Для симметричных (но не обязательно нормальных) распределений
- Когда важна не только направление, но и величина различий
- В экспериментах "до-после" с малыми выборками

**Предположения:**
- Распределение различий симметрично относительно медианы
- Данные измерены как минимум в интервальной шкале
- Более мощный, чем знаковый критерий, при выполнении предположения о симметрии

**Гипотеза H₀:** Med(D) = 0, где D - разности парных наблюдений

**Статистика:**

```text
W⁺ = Σ(знак(dᵢ)>0) rank(|dᵢ|)
```

где:
- `dᵢ` - разности парных наблюдений или отклонения от медианы
- `rank(|dᵢ|)` - ранг абсолютной величины разности
- Суммируются ранги только положительных разностей

Альтернативно можно использовать `W⁻` (сумма рангов отрицательных разностей).

**Решение:**
- Для малых n: используются табличные критические значения
- Для больших n (n > 20): нормальная аппроксимация
  ```
  Z = (W⁺ - n(n+1)/4) / √(n(n+1)(2n+1)/24)
  ```

**Пример использования:**
Тестируется новое лекарство: измерено артериальное давление 25 пациентов до и после приема. Критерий Вилкоксона определит, есть ли значимое изменение давления, учитывая как направление, так и величину изменений у каждого пациента.

#### Критерий Колмогорова-Смирнова

**Назначение:** Проверка соответствия эмпирического распределения теоретическому или сравнение двух эмпирических распределений.

**Когда применяется:**
- Для проверки гипотезы о виде распределения (нормальное, экспоненциальное и т.д.)
- При сравнении распределений двух выборок (двухвыборочный вариант)
- Когда параметры теоретического распределения известны заранее (не оценены по выборке)
- Для непрерывных распределений (плохо работает для дискретных)

**Предположения:**
- Распределение должно быть непрерывным
- Если параметры оценены по выборке, требуется модификация критических значений (критерий Лиллиефорса)
- Менее мощный, чем критерий Андерсона-Дарлинга для нормального распределения

**Гипотеза H₀:** выборка из распределения F(x)

**Статистика:**

```text
D = max|F̂ₙ(x) - F(x)|
```

где:
- `F̂ₙ(x) = k/n` - эмпирическая функция распределения (доля наблюдений ≤ x)
- `F(x)` - теоретическая функция распределения
- D измеряет максимальное вертикальное расстояние между двумя функциями

**Критическое значение:**

```text
D_crit = c(α) / √n
```

где:
- c(0.10) ≈ 1.22
- c(0.05) ≈ 1.36
- c(0.01) ≈ 1.63

**Решение:** Если `D > D_crit`, то H₀ отвергается.

**Пример использования:**
При моделировании случайных чисел необходимо проверить, что генератор действительно создает равномерное распределение на [0,1]. Критерий Колмогорова-Смирнова сравнит эмпирическое распределение 1000 сгенерированных чисел с теоретическим равномерным распределением.

**Модификации:**
- **Критерий Лиллиефорса:** для проверки нормальности, когда параметры оценены по выборке
- **Двухвыборочный тест:** для сравнения распределений двух независимых выборок

#### Критерий Краскела-Уоллиса (сравнение нескольких групп)

**Назначение:** Проверка гипотезы о равенстве распределений в k ≥ 2 группах.

**Когда применяется:**
- Непараметрическая альтернатива однофакторному дисперсионному анализу (ANOVA)
- Когда нарушены предположения ANOVA (ненормальность, неравные дисперсии)
- При сравнении более двух независимых групп
- Для порядковых данных (например, оценки, ранги)
- При наличии выбросов или асимметричных распределений

**Предположения:**
- Независимые выборки
- Переменная измерена хотя бы в порядковой шкале
- Распределения в группах имеют одинаковую форму (но могут отличаться по расположению)

**Гипотеза H₀:** Все k выборок из одного распределения (медианы равны)
**Альтернатива H₁:** Хотя бы одна выборка из другого распределения

**Статистика:**

```text
H = (12/(N(N+1))) Σⱼ(R²ⱼ/nⱼ) - 3(N+1)
```

где:
- `Rⱼ` - сумма рангов в j-й группе (ранги вычисляются для объединенной выборки)
- `nⱼ` - объем j-й группы
- `N = Σⱼ nⱼ` - общий объем выборки

**Распределение:** При достаточно больших выборках (nⱼ ≥ 5) приближенно χ² с (k-1) степенями свободы

**Решение:** Если `H > χ²_α(k-1)`, то H₀ отвергается.

**Post-hoc анализ:** Если H₀ отвергнута, для попарных сравнений используется критерий Данна с поправкой на множественность.

**Пример использования:**
Сравнивается эффективность 5 различных методов обучения: измерены итоговые баллы студентов в каждой группе (по 20 человек). Так как баллы распределены асимметрично с выбросами, ANOVA неприменим. Критерий Краскела-Уоллиса определит, есть ли значимые различия между методами обучения.

**Связь с другими критериями:**
- При k = 2: эквивалентен двухвыборочному критерию Манна-Уитни (Вилкоксона для независимых выборок)
- Обобщение критерия Манна-Уитни на случай более двух групп

### 11. Численные методы оптимизации

#### Метод Нелдера-Мида (симплекс-метод)

Используется для максимизации функции правдоподобия при MLE.

**Алгоритм:**

1. Инициализация: создание начального симплекса из (n+1) точки в n-мерном пространстве
2. Упорядочивание: сортировка вершин по значению функции
3. Отражение: отражение худшей точки через центроид остальных
4. Если улучшение - растяжение вдоль направления отражения
5. Если ухудшение - сжатие симплекса
6. Повторение до достижения сходимости

**Параметры:**
- Коэффициент отражения: α = 1
- Коэффициент растяжения: γ = 2
- Коэффициент сжатия: ρ = 0.5
- Коэффициент редукции: σ = 0.5

**Критерий остановки:**

```text
√(Σᵢ(f(xᵢ) - f̄)² / (n+1)) < ε
```

где f̄ - среднее значение функции на вершинах симплекса

## Используемые технологии

### C++ и библиотеки

- **C++17** - стандарт языка
- **Boost Math** - статистические распределения и функции
- **Boost.uBLAS** - библиотека линейной алгебры для матричных операций
- **Qt 6.9.3** - фреймворк для GUI приложения
- **CMake** - система сборки для GUI

### Python библиотеки

- **NumPy** - численные вычисления
- **Matplotlib** - визуализация графиков
- **SciPy** - дополнительные статистические функции

### Алгоритмы оптимизации

- **Метод Нелдера-Мида** - симплекс-метод для численной оптимизации параметров MLE
- **Метод наименьших квадратов (Агамирова)** - линейная регрессия с медианными рангами

## Очистка

### Linux/macOS

```bash
make clean        # Удалить все скомпилированные файлы
make clean-obj    # Удалить только объектные файлы
```

### Windows

```cmd
mingw32-make -f Makefile.win clean
```

## Устранение неполадок

### Ошибка: "boost/math not found"

Убедитесь что Boost установлен и путь к нему указан правильно:

```bash
# Linux/macOS
export BOOST_ROOT=/path/to/boost

# Windows (в MSYS2)
export BOOST_ROOT=/mingw64
```

### Ошибка: "Python venv not found"

Создайте виртуальное окружение заново (см. раздел Установка).

### Графики не создаются

Проверьте что Python библиотеки установлены:

```bash
python/venv/bin/python -c "import numpy, matplotlib, scipy"
```

## Литература

Реализация основана на классических статистических методах:
- Формулы (2.79), (2.80), (2.83) для доверительных интервалов
- Методы максимального правдоподобия (MLE) и наименьших квадратов (MLS)

## Авторы

- xloned (https://github.com/xloned)
- Assisted by Claude (Anthropic)

## Лицензия

MIT License
